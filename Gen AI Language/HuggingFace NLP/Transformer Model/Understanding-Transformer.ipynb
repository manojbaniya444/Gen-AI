{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNXS3lGXaPwNP5214TRJlUr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["## Encoder Model\n","Encoder model use only the encoder part and at each stage the attention layer can access all the words in the initial sentence.\n","\n","The pretraining of these models usually revolves around somehow corrupting a given sentence and tasking the model with finding or reconstructing the initial sentence for instance by masking random text in it.\n","\n","Encoder model are best suited when understanding the full sentece such as `sentence classification`, `ner`,`extraction` and many more.\n","\n","some encoder model\n","- ALBERT, BERT, DistilBERT, RoBERTa, NepBERT"],"metadata":{"id":"XlpcRGyt8-5v"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","unmasker = pipeline('fill-mask', model='bert-base-uncased')\n","unmasker(\"Hello I'm a [MASK] model.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5j4rBP0aAsRi","executionInfo":{"status":"ok","timestamp":1729177634305,"user_tz":-345,"elapsed":484,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"d615898b-9834-4571-c633-a5b21906668d"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n","- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n","  warnings.warn(\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'score': 0.1073107048869133,\n","  'token': 4827,\n","  'token_str': 'fashion',\n","  'sequence': \"hello i'm a fashion model.\"},\n"," {'score': 0.08774488419294357,\n","  'token': 2535,\n","  'token_str': 'role',\n","  'sequence': \"hello i'm a role model.\"},\n"," {'score': 0.05338384211063385,\n","  'token': 2047,\n","  'token_str': 'new',\n","  'sequence': \"hello i'm a new model.\"},\n"," {'score': 0.04667222499847412,\n","  'token': 3565,\n","  'token_str': 'super',\n","  'sequence': \"hello i'm a super model.\"},\n"," {'score': 0.0270958561450243,\n","  'token': 2986,\n","  'token_str': 'fine',\n","  'sequence': \"hello i'm a fine model.\"}]"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Decoder Model\n","Decode model use the decoder part and at each state for a given word the attention layers can only access the words positioned before the sentence. These models are often called `**auto regressive model**`\n","\n","Best for text generation\n","\n","some decoder model are `**CTRL**`, `**GPT**`, `**TransformerXL**`, `**GPT3**`"],"metadata":{"id":"-PaLM-rR9_nU"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","generator = pipeline('text-generation', model='gpt2')\n","generator(\"Hello, I'm a language model,\", max_length=30, num_return_sequences=5)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"R8AYz74-AxLA","executionInfo":{"status":"ok","timestamp":1729177639755,"user_tz":-345,"elapsed":5452,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"7ae3d6a5-34a9-4dbf-d037-cbd589b95a77"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n","Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': \"Hello, I'm a language model, the project on my website was really, really small and it's just a mess.\\n\\nSo, I\"},\n"," {'generated_text': 'Hello, I\\'m a language model, not a script.\\n\\nI\\'m thinking of the \"language model,\" but I mean very real in a'},\n"," {'generated_text': \"Hello, I'm a language model, just like the concept of an actual computer.\\n\\nIf we were to take the world and build one computer\"},\n"," {'generated_text': 'Hello, I\\'m a language model, not a programming language.\" The author was one of many who agreed to talk—and was still speaking his own'},\n"," {'generated_text': 'Hello, I\\'m a language model, as is the reader; how shall we learn what we mean here?\"\\n\\nThen he said: \"…but'}]"]},"metadata":{},"execution_count":6}]},{"cell_type":"markdown","source":["## Sequence2Sequence Model\n","Encoder-decoer model are such model which use both part of the transformer the attention layer of the encoder can access all the words in the initial sentence where the attention layer of the decoder can only access the word positioned before a given word in the input.\n","\n","Best for task revolving around generating new sentences depending on a given input such as summarization, translation or generative qa.\n","\n","some model are `**BART**`, `mBART`, `Marian`, `T5`"],"metadata":{"id":"90tLvaDl-glF"}},{"cell_type":"code","source":["from transformers import pipeline\n","\n","translator = pipeline(\"translation_en_to_fr\")\n","translator(\"Hugging Face is a technology company based in New York and Paris\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Id7aT1X9A3ci","executionInfo":{"status":"ok","timestamp":1729177646356,"user_tz":-345,"elapsed":3372,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"cc142f1d-c630-4a14-da3e-e27455840790"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stderr","text":["No model was supplied, defaulted to google-t5/t5-base and revision 686f1db (https://huggingface.co/google-t5/t5-base).\n","Using a pipeline without specifying a model name and revision in production is not recommended.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'translation_text': 'Hugging Face est une entreprise technologique basée à New York et à Paris.'}]"]},"metadata":{},"execution_count":8}]},{"cell_type":"code","source":["generator(\"Hi, I am happy\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EAiK6hrOAmfh","executionInfo":{"status":"ok","timestamp":1729177642986,"user_tz":-345,"elapsed":2460,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"2d7ee0f3-3d11-47e0-992d-e32f81f1c333"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': 'Hi, I am happy to report that I am now one of the number 5 on our Top 5 Prospects list, and I am so glad I chose you to be my new team advisor.\\n\\n\"This is my first time ever getting to'}]"]},"metadata":{},"execution_count":7}]},{"cell_type":"markdown","source":["> choose on what we want to achieve"],"metadata":{"id":"rNkzlR0uAZGs"}},{"cell_type":"code","source":["translator(\"happy birthday dear\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lca_RS7TBRsE","executionInfo":{"status":"ok","timestamp":1729177691641,"user_tz":-345,"elapsed":2547,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"20da675e-e563-4356-fcac-ba203cfa7b64"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'translation_text': 'heureux anniversaire cher'}]"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["generator(\"Hello\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DWKBzQFVBREP","executionInfo":{"status":"ok","timestamp":1729177701191,"user_tz":-345,"elapsed":3763,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"0a6ddd6a-c7ae-45d5-a141-ad1a16efbbc0"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"]},{"output_type":"execute_result","data":{"text/plain":["[{'generated_text': \"Hello\\n\\nHi guys, This is an order with this order form.\\n\\n\\nHi\\n\\n\\nThank you so much for your email and I look forward to your reply to the next order. It's time for this order.\\n\\n\\nHere it\"}]"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["translator(\"I love you\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zSIw27sxBcNr","executionInfo":{"status":"ok","timestamp":1729177747787,"user_tz":-345,"elapsed":2831,"user":{"displayName":"Manoj Baniya","userId":"01713573044371624098"}},"outputId":"ac945519-157d-4a1f-86c8-1a9f7de32e48"},"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'translation_text': 'Je vous aime'}]"]},"metadata":{},"execution_count":13}]}]}