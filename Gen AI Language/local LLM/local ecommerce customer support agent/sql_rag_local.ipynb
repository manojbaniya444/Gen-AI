{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "LLM_MODEL_PATH = \"D:\\\\Generative AI\\\\Gen AI Language\\\\local LLM\\\\llama2-7b-q2chat.bin\"\n",
    "EMBEDDING_MODEL_PATH =\"D:\\\\Generative AI\\\\Gen AI Language\\\\local LLM\\\\local embedding\\\\sentence-transformers-local\\\\all-MiniLM-L6-V2\"\n",
    "SQLITE_DATABASE_PATH=\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading LLM Locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import CTransformers\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "llm = CTransformers(\n",
    "    model = LLM_MODEL_PATH,\n",
    "    model_type = \"llama\",\n",
    "    max_new_tokens = 200,\n",
    "    temperature = 0.7,\n",
    ")\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "llm_chain = LLMChain(prompt = prompt, llm = llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Who are you?',\n",
       " 'text': \"I am an AI assistant developed by Meta AI. I'm just an AI, my purpose is to assist and provide helpful responses to your questions. I can answer a wide range of topics, from simple queries to more complex subjects. Feel free to ask me anything!\"}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_chain.invoke({\n",
    "    \"question\": \"Who are you?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Embedding Model Locally\n",
    "First download the model and save it locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name = EMBEDDING_MODEL_PATH\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0028318532276898623,\n",
       " 0.03901991993188858,\n",
       " 0.08902649581432343,\n",
       " 0.07300351560115814,\n",
       " -0.026130713522434235,\n",
       " -0.0733506828546524,\n",
       " 0.055322688072919846,\n",
       " -0.010837383568286896,\n",
       " -0.08899175375699997,\n",
       " 0.017466789111495018]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.embed_query(\"Hello how are you?\")[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities.sql_database import SQLDatabase\n",
    "\n",
    "db = SQLDatabase.from_uri(\"sqlite:///products.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1: SQL Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.agent_toolkits import create_sql_agent\n",
    "\n",
    "agent_executor = create_sql_agent(\n",
    "    llm, \n",
    "    db=db,\n",
    "    agent_type=\"zero-shot-react-description\",\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2: SQL Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "\n",
    "# sql query chain: generates sql query based on given prompt\n",
    "sql_query_chain = create_sql_query_chain(llm, db)\n",
    "\n",
    "# sql validator chain: validate the generated query from sql query chain\n",
    "system = \"\"\"Double check the user's {dialect} query for common mistakes, including:\n",
    "- Using NOT IN with NULL values\n",
    "- Using UNION when UNION ALL should have been used\n",
    "- Using BETWEEN for exclusive ranges\n",
    "- Data type mismatch in predicates\n",
    "- Properly quoting identifiers\n",
    "- Using the correct number of arguments for functions\n",
    "- Casting to the correct data type\n",
    "- Using the proper columns for joins\n",
    "\n",
    "The database contains: \n",
    "table: 'products'\n",
    "with columns in 'products' table:\n",
    "'name': <name of the product>\n",
    "'image_url':<url for the product image>\n",
    "'price': <price of the product>\n",
    "'category': <category of the product (mobile, tv, camera)>\n",
    "'description': <more information about the product>\n",
    "'stock': <current stock items in numbers>\n",
    "\n",
    "If there are any of the above mistakes, rewrite the query.\n",
    "If there are no mistakes, just reproduce the original query with no further commentary.\n",
    "If the query is Data Modification type then return \"Data modification is not allowed\" as the response.\n",
    "\n",
    "otherwise:\n",
    "Output the final SQL query only.\"\"\"\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [(\"system\", system), (\"human\", \"{query}\")]\n",
    ").partial(dialect=db.dialect)\n",
    "validation_chain = prompt | llm | StrOutputParser()\n",
    "\n",
    "sql_chain = {\"query\": sql_query_chain} | validation_chain\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testing the chain\n",
    "sql_chain.invoke({\n",
    "    \"question\": \"How many products are there?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer chain\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Given the following user question, corresponding  SQL query, and the result of the query, answer the question in a short and concise manner.\n",
    "    If asked about product price, description response accordingly only by looking at the <result>. If asked about stock inquiry response according to the sql result. (if 0 then stock is currently unavailable so user cannot order.)\n",
    "    \n",
    "    Question: {question}\n",
    "    SQL Query: {query}\n",
    "    SQL Result: {result}\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "answer_chain = answer_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "query_executor_chain = QuerySQLDataBaseTool(db=db)\n",
    "\n",
    "final_chain = (\n",
    "    RunnablePassthrough.assign(query=sql_chain).assign(result=itemgetter(\"query\") | query_executor_chain)\n",
    "    | answer_chain\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
