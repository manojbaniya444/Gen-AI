{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"\"\"\"\n",
    "Summarize the following question based on the context:\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Context:\n",
    "\n",
    "{context}\n",
    "\n",
    "Response:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUMMARY_PROMPT = ChatPromptTemplate.from_template(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_text(url: str):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "            page_text = soup.get_text(separator=\" \", strip=True)\n",
    "            return page_text\n",
    "        else:\n",
    "            return f\"Failed to retrieve the webpage: Status code {response.status_code}\"\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return f\"Failed to retrieve the webpage: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "url=\"https://www.gitselect.com/post/what-is-langchain-langsmith-and-langserve#:~:text=LangSmith%20and%20LangServe%20are%20integral,of%20your%20LLM%2Dpowered%20applications.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_content = scrape_text(url)[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"What is Langchain, LangSmith and LangServe? top of page Home About AI Cloud Code Learn More Use tab to navigate through the menu items. All Posts Technology AI Cloud Search Log in / Sign up Guest Contributor Feb 20 5 min read What is Langchain, LangSmith and LangServe? The rise of artificial intelligence (AI) has brought about a revolution in numerous industries, leading to the development of innovative tools and platforms. One of the most recent developments in this sphere is LangChain, a unique AI-powered tool that offers a new way to build, observe, and deploy applications. But what is LangChain, and how can it transform the landscape of Language Learning Machines (LLM) and AI? Let's explore this in detail. An Introduction to LangChain LangChain is a development platform and library powered by artificial intelligence. It's specifically designed to aid developers in creating applications based on Language Learning Machines (LLM). The essence of LangChain lies in its ability to transform intricate programming tasks into a more intuitive, user-friendly process. What sets LangChain apart is its unique framework that simplifies the creation of AI-powered applications. With the use of this platform, developers can expediently build apps that utilize LLM, effectively eliminating the usual complexities associated with such undertakings. LangChain is equipped with a suite of tools that provide insight into your application's performance and streamline the deployment of your app, creating an environment that is conducive to efficient and high-quality application development. Through the use of LangChain, developers are provided with a more simplified path towards creating applications that leverage the power of AI and LLM. From designing an app's core features to monitoring its performance and finally deploying it, LangChain has integrated tools to help every step of the way. Its intuitive nature allows for a smoother development process, giving developers more time to focus on the creative aspects of their projects. Use Cases of LangChain LangChain's versatility opens up a myriad of applications across various sectors. Its primary role lies in facilitating the swift and efficient development of LLM-powered applications. For instance, it can be employed in the creation of language education apps, empowering users to acquire new languages with ease. Similarly, customer service bots that converse in multiple languages can be developed using LangChain, enhancing customer interactions and satisfaction. In addition, LangChain can be instrumental in developing machine translation systems that simplify communication across language barriers. Other potential applications include predictive text input tools, voice recognition, and transcription apps. LangChain's capabilities also extend to natural language processing systems, pushing the boundaries of how machines understand and interact with human language. The LangChain framework is thus not only a developer's ally for creating LLM-powered applications but also an enabler of innovative solutions in the realm of language processing and understanding. Whether it's simplifying language learning, enhancing customer service, or breaking down language barriers, the use cases for LangChain are extensive and transformative. The Role of LangSmith and LangServe LangSmith and LangServe are integral parts of the LangChain ecosystem, enhancing its functionality and streamlining the development process. Acting as a transparent lens into your application, LangSmith is instrumental in keeping tabs on the performance and operations of your LLM-powered applications. With LangSmith, you can get valuable insights into your app’s functioning, identifying areas of improvement, and making the necessary adjustments to enhance quality. LangServe, on the other hand, operates as the deployment engine for your application built with LangChain. It delivers turnkey solutions for serving an API for your app, significantly simplifying this usually complex task. LangServe takes away the burden of the technical aspects of deployment, allowing you to focus more on improving your application's functionality and user experience. LangSmith and LangServe, in essence, function as the monitoring and deployment arms of LangChain. They work in tandem to ensure not only the smooth creation of your app but also its efficient deployment and continuous improvement. By providing clarity on your app's performance and simplifying the deployment process, they play a crucial role in helping you deliver a robust, high-quality LLM-powered application. Their integration into the LangChain platform reinforces the tool’s commitment to providing an all-encompassing, user-friendly solution for LLM and AI app development. How to Use LangChain: A Step-by-Step Guide Getting started with LangChain is a seamless process. The LangChain library and framework provides an intuitive, user-friendly environment to construct your LLM-driven application, equipped with numerous tools and resources to guide you along. After your application has been created, the next step involves employing LangSmith. This tool offers a window into your application's performance, allowing you to track crucial metrics and gather insightful data. This data helps to identify potential areas for improvement, assisting you in enhancing the overall quality and efficiency of your app. The final phase of your application's journey involves deployment, and this is where LangServe comes into play. LangServe acts as the deployment mechanism for your LangChain application, offering an uncomplicated solution for API serving. This tool eases the often complex task of deployment, freeing you to devote more time and attention to refining your application's functionality and enhancing the user experience. Throughout this process, remember that LangChain's primary aim is to simplify the building, observation, and deployment stages of LLM-powered application development. By offering an integrated solution with tools like LangSmith and LangServe, LangChain ensures you have the support and resources needed for a smooth and successful app development journey. Examples of LangChain Usage To grasp the practical application of LangChain, let's consider a couple of scenarios. A developer, for instance, who is tasked with creating a language learning application could harness the power of LangChain to easily build an interactive app. This app could use LLM to provide engaging language lessons and exercises. The developer would then use LangSmith to observe how users interact with the app, identify bottlenecks, and improve the app's efficiency based on these insights. Deployment of the app would be handled by LangServe, enabling the developer to concentrate on refining the app's features and user experience based on collected feedback. On the other hand, consider a business aiming to develop a multilingual customer service chatbot. In this case, LangChain could be the optimal platform. The business could use LangChain's framework to construct a bot that comprehends and responds to customer inquiries in various languages. This would not only enhance the accessibility of their customer service but also contribute to improved customer satisfaction. Such practical implementations underscore LangChain's versatility and potential in different use cases. Embracing the Future of LLM and Ai As we navigate the ever-evolving landscape of Language Learning Machines and Artificial Intelligence, LangChain stands out as a formidable ally for developers. Its unique framework, coupled with integrated tools like LangSmith and LangServe, streamlines the creation, monitoring, and deployment of LLM-powered applications. This efficiency results in high-quality apps that can truly revolutionize various sectors, from language education to customer service. By leveraging LangChain, developers and businesses alike can readily harness the immense potential of LLM and AI. The platform's versatility and user-friendly nature make it a valuable tool for driving innovation in language-based applications. With LangChain, we can anticipate the creation of more sophisticated, user-oriented applications that utilize the power of language learning machines. As LangChain continues to advance and adapt to emerging technologies, its scope for application will only broaden. This trajectory paints a promising future for LangChain in the realm of LLM and AI, signaling exciting possibilities ahead. Indeed, LangChain isn't just a platform to keep an eye on - it's a tool that propels us towards a future where language barriers are a thing of the past and interaction between humans and machines is more natural and intuitive than ever before. AI • Technology 294 views 0 comments Post not marked as liked Recent Posts See All Guide to Selecting the Best Vector Database 22 0 comments 0 Post not marked as liked JOIN OUR NEWSLETTER Subscribe Thank you for subscribing! © 2024 MetricApps Pty Ltd. All rights reserved. bottom of page\""
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema.output_parser import StrOutputParser\n",
    "\n",
    "parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Based on the context, the question being asked is:\\n\\n\"What is Langchain?\"'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\n",
    "    \"question\": \"What is langchain?\",\n",
    "    \"context\": page_content\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RunnablePassThrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough.assign(\n",
    "    context = lambda x: scrape_text(x[\"url\"])[:10000]\n",
    ") | prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  context: RunnableLambda(lambda x: scrape_text(x['url'])[:10000])\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\"\\nSummarize the following question based on the context:\\n\\nQuestion: {question}\\n\\nContext:\\n\\n{context}\\n\\nResponse:\\n'))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\n",
    "    \"question\": \"What is langsmith?\",\n",
    "    \"url\": url\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, the question being asked is \"What is Langsmith?\"\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### search API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TAVILY_API_KEY\"] = os.getenv(\"TAVILY_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "search = TavilySearchResults()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search.invoke(\n",
    "#     {\n",
    "#         \"query\": \"What is langchain?\"\n",
    "#     }\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DUCKDUCKGO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import DuckDuckGoSearchAPIWrapper\n",
    "\n",
    "RESULTS_PER_REQUEST = 3\n",
    "\n",
    "ddg_search = DuckDuckGoSearchAPIWrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def web_search(query: str, num_results: int= RESULTS_PER_REQUEST):\n",
    "    results = ddg_search.results(query, num_results)\n",
    "    return [r[\"link\"] for r in results]\n",
    "\n",
    "# this returns a list of links like here\n",
    "# results = [\n",
    "#     {\"link\": \"https://example.com/page1\"},\n",
    "#     {\"link\": \"https://example.com/page2\"},\n",
    "#     {\"link\": \"https://example.com/page3\"}\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://www.geeksforgeeks.org/introduction-to-langchain/',\n",
       " 'https://www.freecodecamp.org/news/beginners-guide-to-langchain/',\n",
       " 'https://www.baeldung.com/java-langchain-basics']"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "web_search(\"What is Langchain?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Introduction to LangChain - GeeksforGeeks Skip to content Tutorials Python Tutorial Taking Input in Python Python Operators Python Data Types Python Numbers Python String Python Lists Python Tuples Sets in Python Python Dictionary Python Loops and Control Flow Python Conditional Statements Python Loops Python Functions Python OOPS Concept Python Data Structures Python DSA Linked List Stack Queue Tree Heap Hashing Graph Sets Map Advance Data Structure Sorting Algorithms Searching Algorithms Python Exception Handling Python File Handling Python Exercises Python List Exercise Python String Exercise Python Tuple Exercise Python Dictionary Exercise Python Set Exercise Python Design Patterns Python Programming Examples Python Practice Questions Java Java Programming Language Java Tutorial Data Types Variables Operators Flow Control in Java Loops in Java Methods Strings Arrays OOPs Concepts OOPs Concepts Classes and Objects Access Modifiers Inheritance Abstraction Encapsulation Polymorphism Interface Packages Multithreading File Handling Regular Expression Java Collections Java Collections Collection Class List Interface ArrayList LinkedList Class Queue Interface Set Interface HashSet Class Map Interface HashMap Class HashTable Class Iterator Comparator Collection Interview Questions Java 8 Tutorial Java Programs Java Programming Examples Java Array Programs Java String Programs Java Date-Time Programs Java File Handling Programs Java Collection Programs Java JDBC Programs Java Apache POI Programs Java OpenCV Programs Java Interview Questions Java Interview Questions Core Java Interview Questions-Freshers Java Multithreading Interview Questions OOPs Interview Questions and Answers Java Exercises Java Quiz Java Quiz Core Java MCQ Java Projects Advance Java Spring Tutorial Spring Boot Tutorial Spring Boot Interview Questions Spring MVC Tutorial Spring MVC Interview Questions Hibernate Tutorial Hibernate Interview Questions Programming Languages C C++ JavaScript PHP R Tutorial C# SQL Scala Perl Go Language Kotlin System Design System Design Tutorial What is System Design Key Terminologies in System Design Analysis and Architecture of Systems Scalability in System Design Databases in System Design High Level Design or HLD Low Level Design or LLD Case Studies in Designing Systems Complete System Design Tutorial Software Design Patterns System Design Roadmap Top 10 System Design Interview Questions and Answers Interview Corner Company Preparation Top Topics Practice Company Questions Interview Experiences Experienced Interviews Internship Interviews Competitive Programming Multiple Choice Quizzes Aptitude for Placements Computer Science Subjects Operating System DBMS Computer Networks Engineering Mathematics Computer Organization and Architecture Theory of Computation Compiler Design Digital Logic Software Engineering DevOps GIT AWS Docker Kubernetes Microsoft Azure Tutorial Google Cloud Platform Linux Linux Tutorial Linux Commands A-Z Linux Commands Cheatsheet File Permission Commands Linux System Administration Linux File System Linux Shell Scripting Linux Networking Linux Interview Questions Software Testing Software Testing Tutorial Software Engineering Tutorial Testing Interview Questions Jira Databases DBMS Tutorial SQL Tutorial PostgreSQL Tutorial MongoDB Tutorial SQL Interview Questions MySQL Interview Questions PL/SQL Interview Questions Android Android Tutorial Android Studio Tutorial Kotlin For Android Android Projects Android Interview Questions 6 Weeks of Android App Development Excel MS Excel Tutorial Introduction to MS Excel Data Analysis in Excel Basic Excel Formulas & Functions Data Analysis in Advanced Excel Workbooks Statistical Functions Data Visualization in Excel Pivot Tables in Excel Excel Spreadsheets in Python Basic Excel Shortcuts Mathematics Number System Algebra Linear Algebra Trigonometry Set Theory Statistics Probability Geometry Mensuration Logarithms Calculus DSA Data Structures Arrays Matrix Strings Linked List Singly Linked List Doubly Linked List Circular Linked List Doubly Circular Linked List Linked List Tutorial Stack Queue Tree Generic Tree Binary Tree Binary Search Tree AVL Tree B Tree B+ Tree Red Black Tree Tree Data Structure Tutorial Heap Hashing Graph Set Data Structure Map Data Structure Advanced Data Structure Data Structures Tutorial Algorithms Analysis of Algorithms Design and Analysis of Algorithms Asymptotic Analysis Asymptotic Notations Worst, Average and Best Cases Searching Algorithms Linear Search Binary Search Searching Algorithms Tutorial Sorting Algorithms Selection Sort Bubble Sort Insertion Sort Merge Sort Quick Sort Heap Sort Counting Sort Radix Sort Bucket Sort Sorting Algorithms Tutorial Greedy Algorithms Dynamic Programming Graph Algorithms Pattern Searching Recursion Backtracking Divide and Conquer Mathematical Algorithms Geometric Algorithms Bitwise Algorithms Randomized Algorithms Branch and Bound Algorithms Tutorial DSA Tutorial Practice All DSA Problems Problem of the Day Company Wise Coding Practice Amazon Microsoft Flipkart Explore All GfG SDE Sheet Practice Problems Difficulty Wise School Basic Easy Medium Hard Language Wise Coding Practice CPP Java Python Curated DSA Lists Beginner's DSA Sheet Top 50 Array Problems Top 50 String Problems Top 50 DP Problems Top 50 Graph Problems Top 50 Tree Problems Competitive Programming Company Wise SDE Sheets Facebook SDE Sheet Amazon SDE Sheet Apple SDE Sheet Netflix SDE Sheet Google SDE Sheet DSA Cheat Sheets SDE Sheet DSA Sheet for Beginners FAANG Coding Sheet Product-Based Coding Sheet Company-Wise Preparation Sheet Top Interview Questions Puzzles All Puzzles Top 100 Puzzles Asked In Interviews Top 20 Puzzles Commonly Asked During SDE Interviews Data Science Python Tutorial R Tutorial Machine Learning Data Science using Python Data Science using R Data Science Packages Pandas Tutorial NumPy Tutorial Data Visualization Python Data Visualization Tutorial Data Visualization with R Data Analysis Data Analysis with Python Data Analysis with R Deep Learning NLP Tutorial Web Tech HTML Tutorial CSS Tutorial JavaScript Tutorial PHP Tutorial ReactJS Tutorial NodeJS Tutorial AngularJS Tutorial Bootstrap Tutorial Typescript Web Development Using Python Django Django Tutorial Django Projects Django Interview Questions Flask Flask Tutorial Flask Projects Flask Interview Questions Postman Github Wordpress Tutorial Web Design Cheat Sheets HTML Cheat Sheet CSS Cheat Sheet JavaScript Cheat Sheet React Cheat Sheet Angular Cheat Sheet jQuery Cheat Sheet Bootstrap Cheat Sheet Learn Complete Web Development Courses Coding for Everyone DSA to Development Machine Learning & Data Science Generative AI & ChatGPT Become AWS Certified DSA Courses Data Structure & Algorithm(C++/JAVA) Data Structure & Algorithm(Python) Data Structure & Algorithm(JavaScript) Programming Languages CPP Java Python JavaScript C AI ML DS Data Science Data Analysis Data Visualization Machine Learning Deep Learning NLP Computer Vision Artificial Intelligence AI ML DS Interview Series AI ML DS Projects series Data Engineering Web Scrapping ▲ Open In App Introduction to LangChain Last Updated : 03 Jun, 2024 Improve Summarize Suggest changes Post a comment Like Article Like Save Share Report LangChain is an open-source framework designed to simplify the creation of applications using large language models (LLMs). It provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications. It allows AI developers to develop applications based on the combined Large Language Models (LLMs) such as GPT-4 with external sources of computation and data. This framework comes with a package for both Python and JavaScript. LangChain follows a general pipeline where a user asks a question to the language model where the vector representation of the question is used to do a similarity search in the vector database and the relevant information is fetched from the vector database and the response is later fed to the language model. further, the language model generates an answer or takes an action. Applications of LangChain LangChain is a powerful tool that can be used to build a wide range of LLM-powered applications. It is simple to use and has a large user and contributor community. Document analysis and summarization Chatbots: LangChain can be used to build chatbots that interact with users naturally. For example, LangChain\\xa0can be used to build a chatbot that can answer client questions, provide customer assistance, and even arrange appointments. Code analysis: LangChain can be used to analyse code and find potential bugs or security flaws. Answering questions using sources: LangChain can be used to answer questions using a variety of sources, including text, code, and data. For example, LangChain can be used to answer questions about a specific topic by searching through a variety of sources, such as Wikipedia, news articles, and code repositories. Data augmentation: LangChain can be used to augment data by generating new data that is similar to existing data. For example, LangChain can be used to generate new text data that is similar to existing text data. This can be useful for training machine learning models or for creating new datasets. Text classification: LangChain can be used for text classifications and sentiment analysis with the text input data Text summarization: LangChain can be used to summarize the text in the specified number of words or sentences. Machine translation: LangChain can be used to translate the input text data into different languages. LangChain Key Concepts: The main properties of LangChain Framework are : Components: Components are modular building blocks that are ready and easy to use to build powerful applications. Components include LLM Wrappers, Prompt Template and Indexes for relevant information retrieval. Chains: Chains allow us to combine multiple components together to solve a specific task. Chains make it easy for the implementation of complex applications by making it more modular and simple to debug and maintain. Agents: Agents allow LLMs to interact with their environment. For example, using an external API to perform a specific action. Setting up the environment Installation of langchain is very simple and similar as you install other libraries using the pip command. !pip install langchain There are various LLMs that you can use with LangChain. In this article, I will be using OpenAI . Let us install Openai using the following command: !pip install openai I am also installing the dotenv library to store the API key in an environmental variable. Install it using the command: !pip install python-dotenv You can generate your own API key by signing up to the openai platform. Next, we create a .env file and store our API key in it as follows: Python OPENAI_KEY = 'your_api_key' Now, I am creating a new file named ‘lang.py’ where I will be using the LangChain framework to generate responses. Let us start by importing the required libraries as follows: Python import os import openai , langchain from dotenv import load_dotenv load_dotenv () api_key = os . getenv ( & quot ; OPENAI_KEY & quot ;, None ) That was the initial setup required to use the LangChain framework with OpenAI LLM. Building an Application As this is an introductory article, let us start by generating a simple answer for a simple question such as “Suggest me a skill that is in demand?”. We start by importing lang-chain and initializing an LLM as follows: Python from langchain.llms import OpenAI llm = OpenAI ( temperature = 0.9 , openai_api_key = api_key ) We are initializing it with a high temperature which means that the results will be random and less accurate. For it to be more accurate you can give a temperature as 0.4 or lesser. We are then assigning openai_api_key as api_key which we have loaded previously from .env file. The next step would be to predict by passing in the text as follows: Python response = llm . predict ( & quot ; Suggest me a skill that is in demand ? & quot ;) print ( response ) That is it! The response generated is as follows: One skill in demand right now is software/web development, which includes everything from coding to content management systems to web design. Other skills in demand include cloud computing, machine learning and artificial intelligence, digital marketing, cybersecurity, data analysis, and project management. Conclusion: That was the basic introduction to langchain framework. I hope you have understood the usage and there are a lot more concepts such as prompt templates, chains and agents to learn. The LangChain framework is a great interface to develop interesting AI-powered applications and from personal assistants to prompt management as well as automating tasks. So, Keep learning and keep developing powerful applications. N namaldesign Follow Improve Next Article Build  Chatbot Webapp with LangChain Please Login to comment... Similar Reads Build  Chatbot Webapp with LangChain LangChain is a Python module that allows you to develop applications powered by language models. It provides a framework for connecting language models to other data sources and interacting with various APIs. LangChain is designed to be easy to use, even for developers who are not familiar with language models. How does Langchain work?LangChain wor 13 min read Introduction to Hill Climbing | Artificial Intelligence Hill climbing is a simple optimization algorithm used in Artificial Intelligence (AI) to find the best possible solution for a given problem. It belongs to the family of local search algorithms and is often used in optimization problems where the goal is to find the best solution from a set of possible solutions. In Hill Climbing, the algorithm sta 11 min read Introduction to ANN (Artificial Neural Networks) | Set 3 (Hybrid Systems) Prerequisites: Genetic algorithms, Artificial Neural Networks, Fuzzy Logic Hybrid systems: A Hybrid system is an intelligent system that is framed by combining at least two intelligent technologies like Fuzzy Logic, Neural networks, Genetic algorithms, reinforcement learning, etc. The combination of different techniques in one computational model m 4 min read ML | Introduction to Data in Machine Learning Data is a crucial component in the field of Machine Learning. It refers to the set of observations or measurements that can be used to train a machine-learning model. The quality and quantity of data available for training and testing play a significant role in determining the performance of a machine-learning model. Data can be in various forms su 10 min read Introduction to Data Science : Skills Required Data science is an interdisciplinary field of scientific methods, processes, algorithms, and systems to extract knowledge or insights from data in various forms, either structured or unstructured, similar to data mining. Big Data Analytics or Data Science is a very common term in the IT industry because everyone knows this is some fancy term that i 6 min read Introduction to ANN | Set 4 (Network Architectures) Prerequisites: Introduction to ANN | Set-1, Set-2, Set-3 An Artificial Neural Network (ANN) is an information processing paradigm that is inspired by the brain. ANNs, like people, learn by examples. An ANN is configured for a specific application, such as pattern recognition or data classification, through a learning process. Learning largely invol 5 min read Introduction to Multi-Task Learning(MTL) for Deep Learning Multi-Task Learning (MTL) is a type of machine learning technique where a model is trained to perform multiple tasks simultaneously. In deep learning, MTL refers to training a neural network to perform multiple tasks by sharing some of the network's layers and parameters across tasks. In MTL, the goal is to improve the generalization performance of 6 min read Introduction to Bootstrap plot Before getting into Bootstrap plot, let us first understand what Bootstrapping (or Bootstrap sampling) is all about. Bootstrap Sampling: It is a method in which we take a sample data repeatedly with replacement from a data set to estimate a population parameter. It is used to determine various parameters of a population. A bootstrap plot is a graph 5 min read Deep Learning with PyTorch | An Introduction PyTorch in a lot of ways behaves like the arrays we love from Numpy. These Numpy arrays, after all, are just tensors. PyTorch takes these tensors and makes it simple to move them to GPUs for the faster processing needed when training neural networks. It also provides a module that automatically calculates gradients (for backpropagation) and another 7 min read ML | Momentum-based Gradient Optimizer introduction Gradient Descent is an optimization technique used in Machine Learning frameworks to train different models. The training process consists of an objective function (or the error function), which determines the error a Machine Learning model has on a given dataset. While training, the parameters of this algorithm are initialized to random values. As 5 min read View More Articles Article Tags : AI-ML-DS Data Science Machine Learning ChatGPT Prompts OpenAI API python Python-Library Python-Miscellaneous +4 More Practice Tags : Machine Learning python Like Explore More Corporate & Communications Address:- A-143, 9th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) | Registered Address:- K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305 Company About Us Legal In Media Contact Us Advertise with us GFG Corporate Solution Placement Training Program GeeksforGeeks Community Languages Python Java C++ PHP GoLang SQL R Language Android Tutorial Tutorials Archive DSA Data Structures Algorithms DSA for Beginners Basic DSA Problems DSA Roadmap Top 100 DSA Interview Problems DSA Roadmap by Sandeep Jain All Cheat Sheets Data Science & ML Data Science With Python Data Science For Beginner Machine Learning Tutorial ML Maths Data Visualisation Tutorial Pandas Tutorial NumPy Tutorial NLP Tutorial Deep Learning Tutorial Web Technologies HTML CSS JavaScript TypeScript ReactJS NextJS Bootstrap Web Design Python Tutorial Python Programming Examples Python Projects Python Tkinter Web Scraping OpenCV Tutorial Python Interview Question Django Computer Science Operating Systems Computer Network Database Management System Software Engineering Digital Logic Design Engineering Maths Software Development Software Testing DevOps Git Linux AWS Docker Kubernetes Azure GCP DevOps Roadmap System Design High Level Design Low Level Design UML Diagrams Interview Guide Design Patterns OOAD System Design Bootcamp Interview Questions Inteview Preparation Competitive Programming Top DS or Algo for CP Company-Wise Recruitment Process Company-Wise Preparation Aptitude Preparation Puzzles School Subjects Mathematics Physics Chemistry Biology Social Science English Grammar Commerce World GK GeeksforGeeks Videos DSA Python Java C++ Web Development Data Science CS Subjects @GeeksforGeeks, Sanchhaya Education Private Limited , All rights reserved We use cookies to ensure you have the best browsing experience on our website. By using our site, you\\r\\n        acknowledge that you have read and understood our Cookie Policy & Privacy Policy Got It ! Improvement Please go through our recently updated Improvement Guidelines before submitting any improvements. This improvement is locked by another user right now. You can suggest the changes for now and it will be under 'My Suggestions' Tab on Write. You will be notified via email once the article is available for improvement.\\r\\n                        Thank you for your valuable feedback! Suggest changes Please go through our recently updated Improvement Guidelines before submitting any improvements. Suggest Changes Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal. Create Improvement Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all. Suggest Changes min 4 words, max CharLimit:2000 Create Improvement What kind of Experience do you want to share? Interview Experiences Admission Experiences Career Journeys Work Experiences Campus Experiences Competitive Exam Experiences Can't choose a topic to write? click here for suggested topics Write and publish your own Article\""
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_text(\"https://www.geeksforgeeks.org/introduction-to-langchain/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_and_summarize_chain = RunnablePassthrough.assign(\n",
    "    context = lambda x: scrape_text(x[\"url\"])[:10000]\n",
    ") | prompt | model | parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  context: RunnableLambda(lambda x: scrape_text(x['url'])[:10000])\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\"\\nSummarize the following question based on the context:\\n\\nQuestion: {question}\\n\\nContext:\\n\\n{context}\\n\\nResponse:\\n'))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_and_summarize_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough.assign(\n",
    "    urls = lambda x: web_search(x[\"question\"])\n",
    ") | (lambda x: [{\"question\": x[\"question\"], \"url\": u} for u in x[\"urls\"]]) | scrape_and_summarize_chain.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  urls: RunnableLambda(lambda x: web_search(x['question']))\n",
       "})\n",
       "| RunnableLambda(...)\n",
       "| RunnableEach(bound=RunnableAssign(mapper={\n",
       "    context: RunnableLambda(lambda x: scrape_text(x['url'])[:10000])\n",
       "  })\n",
       "  | ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\"\\nSummarize the following question based on the context:\\n\\nQuestion: {question}\\n\\nContext:\\n\\n{context}\\n\\nResponse:\\n'))])\n",
       "  | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "  | StrOutputParser())"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\n",
    "    \"question\": \"what is Langchain and LangSmith?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the context, the question \"What is Langchain and LangSmith?\" is asking about the differences and purposes of two AI language model tools, Langchain and LangSmith.\n",
      "\n",
      "Langchain is described as a versatile open-source framework that enables developers to build applications using large language models (LLM) like GPT-3. It provides a standardized interface for chains and supports creating complex chains for various applications.\n",
      "\n",
      "LangSmith, on the other hand, is built on top of Langchain and is described as a dashboard that helps monitor and debug the performance of LLM applications. It provides features such as in-depth debugging capabilities, evaluation and monitoring tools, and facilitates production-grade application development.\n",
      "\n",
      "In summary, Langchain is a framework for building LLM applications, while LangSmith is a tool for monitoring and debugging those applications.\n",
      "I apologize, but there is no context provided, as the response is a \"Failed to retrieve the webpage: Status code 403\" error message, which means the webpage or resource could not be accessed. Therefore, I cannot summarize the question based on the context.\n",
      "Based on the context, the question being asked is: \"What is Langchain and LangSmith?\"\n",
      "\n",
      "Langchain is an open-source framework for building and testing Language Learning Models (LLMs), while LangSmith is a platform that offers a range of features for debugging, testing, evaluating, and monitoring LLM applications. LangSmith is designed to elevate LLM applications to production-grade quality and provides a toolkit for building, testing, and deploying intelligent agents and chains based on any LLM framework.\n"
     ]
    }
   ],
   "source": [
    "for r in response:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLM Prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEARCH_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        # (\"system\", \"{agent_prompt}\"),\n",
    "        (\n",
    "            \"user\",\n",
    "            \"Write 3 google search queries to search form an\"\n",
    "            \"Objective opinion from the following: {question}\\n\"\n",
    "            \"You must response with a list of strings in the following format: \"\n",
    "            \"['query 1', 'query 2', 'query 3']\"\n",
    "            \"only return the list and nothing else.\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['items']\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "\n",
    "# def get_list(response: str):\n",
    "#     string = 'hello these are items [\"items\"] how you like it'\n",
    "#     items = re.findall(r'\\[\"([^\"]+)\"\\]', string)\n",
    "\n",
    "#     print(items)\n",
    "    \n",
    "# get_list(\"\"\"Here are three Google search queries to search for an objective opinion on the difference between LangChain and LangSmith:\n",
    "\n",
    "# ['\"difference between LangChain and LangSmith\" site:researchpapers.io', 'What are the key features of LangChain vs LangSmith', 'Comparison of LangChain and LangSmith: Which is better for language processing?']\n",
    "\n",
    "# These queries aim to:\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_question_chain = SEARCH_PROMPT | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"Write 3 google search queries to search form anObjective opinion from the following: {question}\\nYou must response with a list of strings in the following format: ['query 1', 'query 2', 'query 3']only return the list and nothing else.\"))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_question_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = search_question_chain.invoke({\n",
    "    \"question\": \"What is the difference between langchain and langsmith?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Langchain vs Langsmith comparison', 'What are the key differences between Langchain and Langsmith', 'Objectively comparing Langchain and Langsmith AI models']\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_chain = RunnablePassthrough.assign(\n",
    "    urls= lambda x: web_search(x[\"question\"])\n",
    ") | (lambda x: [{\"question\": x[\"question\"], \"url\": u} for u in x[\"urls\"]]) | scrape_and_summarize_chain.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = search_question_chain | (lambda x: [{\"question\": q} for q in x]) | web_search_chain.map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"Write 3 google search queries to search form anObjective opinion from the following: {question}\\nYou must response with a list of strings in the following format: ['query 1', 'query 2', 'query 3']only return the list and nothing else.\"))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(lambda x: [{'question': q} for q in x])\n",
       "| RunnableEach(bound=RunnableAssign(mapper={\n",
       "    urls: RunnableLambda(lambda x: web_search(x['question']))\n",
       "  })\n",
       "  | RunnableLambda(...)\n",
       "  | RunnableEach(bound=RunnableAssign(mapper={\n",
       "      context: RunnableLambda(lambda x: scrape_text(x['url'])[:10000])\n",
       "    })\n",
       "    | ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\"\\nSummarize the following question based on the context:\\n\\nQuestion: {question}\\n\\nContext:\\n\\n{context}\\n\\nResponse:\\n'))])\n",
       "    | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "    | StrOutputParser()))"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chain.invoke({\n",
    "    \"question\": \"What is the difference between langchain and langsmith?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESEARCH PROMPT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "WRITER_SYSTEM_PROMPT = \"You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESEARCH_REPORT_TEMPLATE = \"\"\"Information:\n",
    "--------\n",
    "{research_summary}\n",
    "--------\n",
    "Using the above information, answer the following question or topic: \"{question}\" in a detailed report -- \\\n",
    "The report should focus on the answer to the question, should be well structured, informative, \\\n",
    "in depth, with facts and numbers if available and a minimum of 1,200 words.\n",
    "You should strive to write the report as long as you can using all relevant and necessary information provided.\n",
    "You must write the report with markdown syntax.\n",
    "You MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\n",
    "Write all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\n",
    "You must write the report in apa format.\n",
    "Please do your best, this is very important to my career.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", WRITER_SYSTEM_PROMPT),\n",
    "        (\"user\", RESEARCH_REPORT_TEMPLATE),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"Write 3 google search queries to search form anObjective opinion from the following: {question}\\nYou must response with a list of strings in the following format: ['query 1', 'query 2', 'query 3']only return the list and nothing else.\"))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()\n",
       "| RunnableLambda(lambda x: [{'question': q} for q in x])\n",
       "| RunnableEach(bound=RunnableAssign(mapper={\n",
       "    urls: RunnableLambda(lambda x: web_search(x['question']))\n",
       "  })\n",
       "  | RunnableLambda(...)\n",
       "  | RunnableEach(bound=RunnableAssign(mapper={\n",
       "      context: RunnableLambda(lambda x: scrape_text(x['url'])[:10000])\n",
       "    })\n",
       "    | ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\"\\nSummarize the following question based on the context:\\n\\nQuestion: {question}\\n\\nContext:\\n\\n{context}\\n\\nResponse:\\n'))])\n",
       "    | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "    | StrOutputParser()))"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_research_chain = search_question_chain | (lambda x: [{\"question\": q} for q in x]) | web_search_chain.map()\n",
    "full_research_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collapse_list_of_lists(list_of_lists):\n",
    "    content = []\n",
    "    for l in list_of_lists:\n",
    "        content.append(\"\\n\\n\".join(l))\n",
    "    return \"\\n\\n\".join(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnablePassthrough.assign(\n",
    "    research_summary=full_research_chain | collapse_list_of_lists\n",
    ") | prompt | model | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  research_summary: ChatPromptTemplate(input_variables=['question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question'], template=\"Write 3 google search queries to search form anObjective opinion from the following: {question}\\nYou must response with a list of strings in the following format: ['query 1', 'query 2', 'query 3']only return the list and nothing else.\"))])\n",
       "                    | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "                    | StrOutputParser()\n",
       "                    | RunnableLambda(lambda x: [{'question': q} for q in x])\n",
       "                    | RunnableEach(bound=RunnableAssign(mapper={\n",
       "                        urls: RunnableLambda(lambda x: web_search(x['question']))\n",
       "                      })\n",
       "                      | RunnableLambda(...)\n",
       "                      | RunnableEach(bound=RunnableAssign(mapper={\n",
       "                          context: RunnableLambda(lambda x: scrape_text(x['url'])[:10000])\n",
       "                        })\n",
       "                        | ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\"\\nSummarize the following question based on the context:\\n\\nQuestion: {question}\\n\\nContext:\\n\\n{context}\\n\\nResponse:\\n'))])\n",
       "                        | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "                        | StrOutputParser()))\n",
       "                    | RunnableLambda(collapse_list_of_lists)\n",
       "})\n",
       "| ChatPromptTemplate(input_variables=['question', 'research_summary'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], template='You are an AI critical thinker research assistant. Your sole purpose is to write well written, critically acclaimed, objective and structured reports on given text.')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['question', 'research_summary'], template='Information:\\n--------\\n{research_summary}\\n--------\\nUsing the above information, answer the following question or topic: \"{question}\" in a detailed report -- The report should focus on the answer to the question, should be well structured, informative, in depth, with facts and numbers if available and a minimum of 1,200 words.\\nYou should strive to write the report as long as you can using all relevant and necessary information provided.\\nYou must write the report with markdown syntax.\\nYou MUST determine your own concrete and valid opinion based on the given information. Do NOT deter to general and meaningless conclusions.\\nWrite all used source urls at the end of the report, and make sure to not add duplicated sources, but only one reference for each.\\nYou must write the report in apa format.\\nPlease do your best, this is very important to my career.'))])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "scrape_and_summarize_chain = RunnablePassthrough.assign(\n",
    "    summary = RunnablePassthrough.assign(\n",
    "        context= lambda x: scrape_text(x[\"url\"])[:10000]\n",
    "    ) | SUMMARY_PROMPT | model | StrOutputParser()\n",
    ") | (lambda x: f\"URL: {x[\"url\"]}\\n\\nSUMMARY: {x[\"summary\"]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableAssign(mapper={\n",
       "  summary: RunnableAssign(mapper={\n",
       "             context: RunnableLambda(lambda x: scrape_text(x['url'])[:10000])\n",
       "           })\n",
       "           | ChatPromptTemplate(input_variables=['context', 'question'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], template='\"\\nSummarize the following question based on the context:\\n\\nQuestion: {question}\\n\\nContext:\\n\\n{context}\\n\\nResponse:\\n'))])\n",
       "           | ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x00000218EC702D80>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x00000218EC7B9790>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "           | StrOutputParser()\n",
       "})\n",
       "| RunnableLambda(...)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scrape_and_summarize_chain"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
