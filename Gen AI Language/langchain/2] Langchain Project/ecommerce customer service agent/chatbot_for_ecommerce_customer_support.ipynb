{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"GROQ_API_KEY\"] = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading LLM model and Embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python312\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-8b-8192\"\n",
    ")\n",
    "\n",
    "embedding_model = SentenceTransformer(\"./sentence-transformers-local/all-miniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01080922, -0.09723883,  0.01275732, -0.04699858, -0.02833704,\n",
       "        0.05745238, -0.01973694,  0.03022125,  0.03715058, -0.0367018 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_model.encode(\"Large Language Model\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello there! It's nice to meet you. I'm a large language model (LLM), trained to understand and generate human-like text. I'm here to assist you with any questions or topics you'd like to discuss. What's on your mind?\", response_metadata={'token_usage': {'completion_tokens': 53, 'prompt_tokens': 14, 'total_tokens': 67, 'completion_time': 0.041140501, 'prompt_time': 0.003943335, 'queue_time': None, 'total_time': 0.045083836}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_af05557ca2', 'finish_reason': 'stop', 'logprobs': None}, id='run-c271c3ec-3bf8-40fc-8c5a-c4819ce1a3c1-0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello, llm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\acer\\AppData\\Roaming\\Python\\Python312\\site-packages\\langchain_core\\_api\\deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "embedding = HuggingFaceEmbeddings(\n",
    "    model_name=\"./sentence-transformers-local/all-miniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.010809220373630524,\n",
       " -0.09723883122205734,\n",
       " 0.012757323682308197,\n",
       " -0.046998582780361176,\n",
       " -0.028337037190794945,\n",
       " 0.05745238438248634,\n",
       " -0.019736938178539276,\n",
       " 0.030221253633499146,\n",
       " 0.03715058043599129,\n",
       " -0.03670179843902588]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding.embed_query(\"Large Language Model\")[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain_community.utilities import SQLDatabase\n",
    "from langchain_community.tools.sql_database.tool import QuerySQLDataBaseTool\n",
    "from langchain.chains import create_sql_query_chain\n",
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from operator import itemgetter\n",
    "from langchain_pinecone import PineconeVectorStore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SQL Chain: (NLP to SQL query to execute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_path = \"./products.db\"\n",
    "db = SQLDatabase.from_uri(f\"sqlite:///{db_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_query(text):\n",
    "    # Define the regular expression to find the SQL query part\n",
    "    pattern = r'SQLQuery:\\s*(.*)'\n",
    "    match = re.search(pattern, text)\n",
    "    \n",
    "    if match:\n",
    "        return match.group(1)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_query = create_sql_query_chain(llm, db)\n",
    "extract_sql_query = RunnableLambda(lambda x: extract_query(x))\n",
    "query_getter = write_query | extract_sql_query\n",
    "execute_query = QuerySQLDataBaseTool(db=db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_prompt = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    \"You are customer service agent for an e-commerce store located in Nepal.The store sell electronics and gadgets and you are chatting with a customer who need help.\n",
    "    Given the following user question, corresponding  SQL query, and the result of the query, respond to the user with the suitable answer to the question without adding anything up in a short and concise manner as possible.\n",
    "    \n",
    "    If the SQL Result is empty, dont try to make up answer, just negate the user question.\n",
    "    \n",
    "    Question: <question>{question}</question>\n",
    "    SQL Query: <query>{query}</query>\n",
    "    SQL Result: <result>{result}</result>\n",
    "    Answer:\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "answer_chain = answer_prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_chain = (\n",
    "    RunnablePassthrough.assign(query=query_getter).assign(result=itemgetter(\"query\") | execute_query)\n",
    "    | answer_chain\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are 9 products available in our store.'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_chain.invoke({\n",
    "    \"question\": \"How many products are there?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG CHAIN: (retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"PINECONE_API_KEY\"] = os.environ[\"PINECONE_API_KEY\"]\n",
    "index_name = \"storeagent\"\n",
    "\n",
    "vectorstore = PineconeVectorStore(\n",
    "    index_name=index_name,\n",
    "    embedding=embedding,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='## What are the delivery options\\n- The delivery  options is available all over Nepal and the delivery charge is Rs. 120 standard price and delivery is free inside Dharan area.', metadata={'source': 'info.txt'}),\n",
       " Document(page_content='## How long the delivery takes\\n- The delivery takes about 2-3 days for all over Nepal and if you are within Dharan Delivery will be the same day you order product.', metadata={'source': 'info.txt'})]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\n",
    "        \"k\":2\n",
    "    }\n",
    ")\n",
    "retriever.invoke(\"Delivery options\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_system_prompt = (\n",
    "    \"You are customer service agent for an e-commerce store.\"\n",
    "    \"The store sell electronics and gadgets and you are chatting with a customer who need help.\"\n",
    "    \"Use the retrieved information or chat history to answer the customer's question.\"\n",
    "    \"If the retrieved information is not useful or the chat history is not relevant, you can ignore it and just answer the question.\"\n",
    "    \"but remember you only answer about the store and questions related to it and nothing else.\"\n",
    "    \"If asked anything else just say that you are just customer service agent and you can only answer about the store.\"\n",
    "    \"\\n\\n\"\n",
    "    \"{context}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", chat_system_prompt),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_chain = create_stuff_documents_chain(\n",
    "    llm,\n",
    "    chat_prompt\n",
    ")\n",
    "\n",
    "rag_chain = create_retrieval_chain(\n",
    "    retriever, # retrieve documents\n",
    "    chat_chain # get the retrieved documents and pass it to LLM to answer the question\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification Chain: (inquiry or info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a customer service agent who is expert in classifying the customer questions in ecommerce store.\"),\n",
    "        (\"human\", \"Classify the question: {question} as one of the following:\\n1. 'product_inquiry': If the customer is asking about specific product price, product details or product stock only.\\n2. 'general_information': If the customer is asking about the store information, store location, store policies or anything that is general information only about the store.\\n3. 'others': If the question does not fall in any of the above categories and is likely out of topic for a customer support service of ecommerce store.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_chain = classifier_template | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Final Chain: RAG + SQL (conditional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_chain = PromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Respond to the user that you dont answer that question as you are a customer service agent and you can only answer about the store.\n",
    "    \"\"\"\n",
    ") | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def route(info):\n",
    "    print(info)\n",
    "    if \"general_information\" in info[\"topic\"].lower():\n",
    "        question = info[\"question\"]\n",
    "        return RunnableLambda(lambda x: {\"input\": question}) | rag_chain | RunnableLambda(lambda x: x[\"answer\"])\n",
    "    elif \"product_inquiry\" in info[\"topic\"].lower():\n",
    "        return sql_chain\n",
    "    else:\n",
    "        return general_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_rag_chain = {\n",
    "    \"topic\": classification_chain,\n",
    "    \"question\": lambda x: x[\"question\"]\n",
    "} | RunnableLambda(route)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing our final chain: (sql_rag_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(question):\n",
    "    return sql_rag_chain.invoke({\"question\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'I would classify the question \"Hello\" as \\'general_information\\'.', 'question': 'Hello'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! Welcome to All Electronics Store's customer service. How can I assist you today?\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'I would classify the question \"Who are you?\" as \\'general_information\\'. The question is asking about the identity or background of the customer service agent, which falls under the category of general information about the store.', 'question': 'Who are you?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! I'm a customer service agent for an e-commerce store that sells electronics and gadgets. I'm here to help answer any questions you have about our products, services, or policies.\""
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Who are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'I would classify the question \"What this store sell?\" as \\'general_information\\'. The customer is asking about the overall nature of the store\\'s products, which is a general piece of information about the store.', 'question': 'What this store sell?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hello! According to our store's information, we sell a wide range of electronics and gadgets, including smartphones, cameras, laptops, PCs, and calculators.\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What this store sell?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'I would classify the question \"What is the return policy?\" as:\\n\\n2. \\'general_information\\'\\n\\nThe customer is asking about the store\\'s return policy, which is a general information about the store\\'s policies. This type of question is not specific to a particular product, but rather about the store\\'s overall policy.', 'question': 'What is the return policy'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Our return policy allows customers to return products within 3 days after receiving their shipment. The product must be in the same condition as when it was purchased, meaning it should be in its original packaging and condition. If the product meets these conditions, we will be happy to assist with the return process.'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is the return policy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'I would classify the question \"Do you have redmi note 9 pro in your store?\" as:\\n\\n1. \\'product_inquiry\\'\\n\\nThe customer is asking about the availability of a specific product (Redmi Note 9 Pro) in the store, which falls under the category of product inquiry.', 'question': 'Do you have redmi note 9 pro in your store>'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, we have Redmi Note 9 Pro in our store.'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"Do you have redmi note 9 pro in your store>\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'I would classify the question \"What is the price of calculator in your store?\" as:\\n\\n1. \\'product_inquiry\\'\\n\\nThe customer is specifically asking about the price of a calculator in the store, which falls under the category of product inquiry.', 'question': 'What is the price of calculator in your store?'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Thank you for reaching out to us! According to our records, the price of the calculator in our store is NPR 1200.'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is the price of calculator in your store?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'topic': 'I would classify the question \"What is the full form of AI?\" as \\'general_information\\'. This question falls under the category of general information, as it is not related to a specific product or store policies, but rather an inquiry about a general topic (Artificial Intelligence).', 'question': 'What is the full form of AI>'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Hi there! I'm happy to help you with your question. However, I'd like to clarify that AI is not related to our e-commerce store that sells electronics and gadgets. As a customer service agent, I can only provide information related to our store. If you'd like to know more about AI, I'd be happy to help you find a resource that can provide more information on that topic.\\n\\nBut if you'd like to know more about the AI-related products we sell in our store, I'd be happy to help you with that!\""
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat(\"What is the full form of AI>\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
