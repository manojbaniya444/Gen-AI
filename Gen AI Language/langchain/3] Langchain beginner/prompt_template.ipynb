{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"GROQ_API_KEY\"] = os.environ[\"GROQ_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Template\n",
    "\n",
    "`PROMPT`: Generate {joke_numbers} jokes about {joke_topic}\n",
    "\n",
    "`Input`:\n",
    "{\n",
    "    \"joke_numbers\" : 7,\n",
    "    \"joke_topic\": \"cats\"\n",
    "}\n",
    "\n",
    "`Output`:\n",
    "Generate 7 jokes about cats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Tell me a joke about cats.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"Tell me a joke about {topic}.\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template) \n",
    "\n",
    "prompt = prompt_template.invoke(\n",
    "    {\n",
    "        \"topic\": \"cats\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='Tell me 7 jokes about cats.')]\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = \"Tell me {number} jokes about {topic}.\"\n",
    "prompt_template = ChatPromptTemplate.from_template(template=template)\n",
    "\n",
    "prompt = prompt_template.invoke(\n",
    "    {\n",
    "        \"number\": 7,\n",
    "        \"topic\": \"cats\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are a assistant who tells jokes about cats.'), HumanMessage(content='Tell me 7 jokes.')]\n"
     ]
    }
   ],
   "source": [
    "# Prompt with System and Human Messages\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "\n",
    "# here using tuple is compulsory with system and human string.\n",
    "messages = [\n",
    "    (\"system\", \"You are a assistant who tells jokes about {topic}.\"),\n",
    "    (\"human\", \"Tell me {number} jokes.\")\n",
    "]\n",
    "\n",
    "# This is same as\n",
    "messages2 = [\n",
    "    SystemMessage(content=\"You are a assistant who tells jokes about cats\"),\n",
    "    HumanMessage(content=\"Tell me 7 jokes.\")\n",
    "]\n",
    "\n",
    "# But dynamic\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke(\n",
    "    {\n",
    "        \"topic\": \"cats\",\n",
    "        \"number\": 7\n",
    "    }\n",
    ")\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Prompt Template with Chat Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are 7 short jokes about cats:\n",
      "\n",
      "1. Why did the cat join a band? Because it wanted to be the purr-cussionist!\n",
      "2. Why did the cat go to the vet? To get its paws-itive diagnosis!\n",
      "3. What did the cat say when it was hungry? \"I'm feline a little peckish!\"\n",
      "4. Why did the cat climb up the tree? To paw-sitively get away from its owner!\n",
      "5. Why did the cat go to the gym? To get some paws-itive reinforcement!\n",
      "6. What did the cat say when it saw a mouse? \"Oh, great. Just what I needed. Another thing to chase!\"\n",
      "7. Why did the cat go to the beauty parlor? To get a paws-itively gorgeous haircut!\n"
     ]
    }
   ],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain_core.messages import SystemMessage, HumanMessage\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a comedian who will tell jokes about {topic}.\"),\n",
    "    (\"human\", \"Tell me {number} short jokes.\")\n",
    "]\n",
    "prompt_template = ChatPromptTemplate.from_messages(messages)\n",
    "prompt = prompt_template.invoke(\n",
    "    {\n",
    "        \"topic\": \"cats\",\n",
    "        \"number\": 7\n",
    "    }\n",
    ")\n",
    "# print(prompt)\n",
    "result = model.invoke(prompt)\n",
    "response = result.content\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
