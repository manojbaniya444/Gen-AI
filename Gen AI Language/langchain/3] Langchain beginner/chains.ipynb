{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = os.environ[\"GROQ_API_KEY\"]\n",
    "\n",
    "model = ChatGroq(model=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Chains : Prompt Template and model and Output Parser with LCEL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content='Tell me 3 things about dogs.')])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.schema.output_parser import StrOutputParser \n",
    "\n",
    "template1 = \"Tell me {number} things about {topic}.\"\n",
    "\n",
    "prompt1 = ChatPromptTemplate.from_template(template1)\n",
    "prompt1.invoke({\n",
    "    \"number\": 3,\n",
    "    \"topic\": \"dogs\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[SystemMessage(content='You are a advisor who will tell 3 things about:'), HumanMessage(content='Tell the topic in dogs')])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is for the template from messages\n",
    "\n",
    "template2 = [\n",
    "    (\"system\", \"You are a advisor who will tell {number} things about:\"),\n",
    "    (\"human\", \"Tell the topic in {topic}\")\n",
    "]\n",
    "prompt2 = ChatPromptTemplate.from_messages(template2)\n",
    "prompt2.invoke(\n",
    "    {\n",
    "        \"number\": 3,\n",
    "        \"topic\": \"dogs\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = prompt1 | model | StrOutputParser()\n",
    "\n",
    "# Running chain prompt1 -> model -> output parser will get the model response content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three things about dogs:\n",
      "\n",
      "1. **Dogs have a powerful sense of smell**: Dogs have up to 300 million olfactory receptors in their noses, compared to only 6 million in humans. This means they can detect smells that are too subtle for us to detect, and they use their sense of smell to navigate their environment and detect pheromones.\n",
      "2. **Dogs are social animals**: Dogs are pack animals that thrive on social interaction with their human family and other dogs. They are naturally inclined to form close bonds with their pack members and enjoy activities like playing, cuddling, and going on walks together.\n",
      "3. **Dogs are highly trainable**: Dogs are capable of learning a wide range of behaviors and tricks due to their ability to associate actions with rewards. They are often used as service animals, search and rescue dogs, and therapy dogs because of their ability to learn complex tasks and respond to commands.\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke({\n",
    "    \"number\": 3,\n",
    "    \"topic\": \"dogs\"\n",
    "})\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structured output parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using structured output parser\n",
    "\n",
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"answer to the user's question nicely.\")\n",
    "]\n",
    "\n",
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // answer to the user\\'s question nicely.\\n}\\n```'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n",
    "format_instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // answer to the user\\'s question nicely.\\n}\\n```'}, template='answer the users question as best as possible.\\n{format_instructions}\\n{question}')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt3 = PromptTemplate(\n",
    "    template=\"answer the users question as best as possible.\\n{format_instructions}\\n{question}\",\n",
    "    input_variables=[\"question\"],\n",
    "    partial_variables={\"format_instructions\": format_instructions}\n",
    ")\n",
    "prompt3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['question'], partial_variables={'format_instructions': 'The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\\n\\n```json\\n{\\n\\t\"answer\": string  // answer to the user\\'s question nicely.\\n}\\n```'}, template='answer the users question as best as possible.\\n{format_instructions}\\n{question}')\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000002BEFBCAD970>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000002BEFBCAE390>, model_name='llama3-8b-8192', groq_api_key=SecretStr('**********'))\n",
       "| StructuredOutputParser(response_schemas=[ResponseSchema(name='answer', description=\"answer to the user's question nicely.\", type='string')])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_structured_output = prompt3 | model | output_parser\n",
    "chain_structured_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'answer': 'Computer Vision is a field of study that focuses on enabling computers to interpret and understand visual information from the world. It is a subfield of Artificial Intelligence (AI) that involves developing algorithms and techniques to extract meaningful information from images, videos, and other visual data. Computer Vision is used in a wide range of applications, including facial recognition, object detection, image classification, segmentation, and image generation. It has many practical uses in areas such as robotics, healthcare, security, and driver assistance systems.'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_structured_output.invoke(\n",
    "    {\n",
    "        \"what is Computer Vision?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output is due to \n",
    "`\n",
    "response_schemas = [\n",
    "    ResponseSchema(name=\"answer\", description=\"answer to the user's question nicely.\")\n",
    "]\n",
    "`\n",
    "\n",
    "we can add more ResponseSchema in a list to create a more structured output as we want"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chains: Under the Hood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three things about dogs:\n",
      "\n",
      "1. **Dogs have a powerful sense of smell**: Dogs have up to 300 million olfactory receptors in their noses, compared to only 6 million in humans. This allows them to detect scents that are too faint for us to detect, and to track smells over long distances.\n",
      "2. **Dogs are highly social animals**: Dogs are pack animals that thrive on social interaction. They are naturally inclined to live in groups and to form close bonds with their human family members. This is why they are often described as \"man's best friend\".\n",
      "3. **Dogs can hear sounds that are too high for humans to hear**: Dogs can hear sounds with frequencies as high as 40,000 to 50,000 Hz, while humans can only hear sounds up to around 20,000 Hz. This means that dogs can pick up on high-pitched sounds like squeaky toys or even ultrasonic dog whistles that are beyond our range of hearing.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.runnables import RunnableLambda, RunnableSequence\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"Tell me {number} things about {topic}.\"\n",
    "prompt_template = PromptTemplate(\n",
    "    template=template,\n",
    "    input_variables=[\"topic\"]\n",
    ")\n",
    "\n",
    "# Runnable lambda\n",
    "prompt = RunnableLambda(lambda x: prompt_template.format_prompt(**x))\n",
    "invoke_model = RunnableLambda(lambda x: model.invoke(x.to_messages()))\n",
    "parse_output = RunnableLambda(lambda x: x.content)\n",
    "\n",
    "# Runnable sequence\n",
    "chain = RunnableSequence(first=prompt, middle=[invoke_model], last=parse_output)\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"number\": 3,\n",
    "    \"topic\": \"dogs\"\n",
    "})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown of what happened in each Runnable Lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### prompt:\n",
    "Here the input from chain.invoke is passed as `x` as a parameter in the lambda function and then the `prompt_template` `format_prompt` replaces the variables in the template to a string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StringPromptValue(text='Tell me 3 things about dogs.')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what happen in the first RunnableLambda above\n",
    "\n",
    "prompt = prompt_template.format_prompt(**{\"topic\": \"dogs\", \"number\": 3})\n",
    "prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### invoke_model:\n",
    "Here the output from first Runnable is pass to the invoke_model Runnable as a parameter x  in which the prompt is formatted to `langchains HumanMessage Format`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Tell me 3 things about dogs.')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This is what happen in the second RunnableLambda above\n",
    "\n",
    "prompt.to_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are three things about dogs:\\n\\n1. **Dogs are incredibly social animals**: Dogs are pack animals that thrive on interaction with their human family and other dogs. They are naturally inclined to form close bonds with their pack, which is why they often become so attached to their owners.\\n2. **Dogs have a powerful sense of smell**: Dogs have up to 300 million olfactory receptors in their noses, compared to only 6 million in humans. This means they can detect smells that are too faint for us to detect, and they use their sense of smell to navigate their environment, detect food, and even detect health issues in their owners.\\n3. **Dogs are highly trainable**: Dogs are able to learn a wide range of behaviors and tasks through training and conditioning. They are capable of learning hundreds of commands and tasks, from simple obedience behaviors like \"sit\" and \"stay\" to complex tasks like search and rescue, agility, and service work. Their ability to learn and adapt makes them valuable companions and working animals.', response_metadata={'token_usage': {'completion_tokens': 209, 'prompt_tokens': 18, 'total_tokens': 227, 'completion_time': 0.170292781, 'prompt_time': 0.00343152, 'queue_time': None, 'total_time': 0.173724301}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-84a3ccae-995b-4f8f-9902-f9d068f03476-0')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = model.invoke(prompt.to_messages())\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Here are three things about dogs:\\n\\n1. Dogs are highly social animals and thrive on interaction with their human family members. They are pack animals and have an instinct to belong to a group, which is why they often form strong bonds with their owners.\\n2. Dogs have a unique sense of smell that is up to 10,000 times more sensitive than that of humans. They use their sense of smell to navigate their environment, detect food and toys, and even recognize their owners.\\n3. Dogs are able to dream just like humans do. Studies have shown that dogs go through different stages of sleep, including REM sleep, during which they experience vivid dreams. This is thought to be an important part of their learning and memory consolidation process.', response_metadata={'token_usage': {'completion_tokens': 149, 'prompt_tokens': 18, 'total_tokens': 167, 'completion_time': 0.121219083, 'prompt_time': 0.003484648, 'queue_time': None, 'total_time': 0.12470373100000001}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'stop', 'logprobs': None}, id='run-b097085a-44f6-4503-8ac1-18b234b11c98-0')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "model.invoke([\n",
    "    HumanMessage(\"Tell me 3 things about dogs.\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### output_parser:\n",
    "Here the output from the model is passed as a parameter x and it is parsed i.e the content portion is extracted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are three things about dogs:\n",
      "\n",
      "1. **Dogs are incredibly social animals**: Dogs are pack animals that thrive on interaction with their human family and other dogs. They are naturally inclined to form close bonds with their pack, which is why they often become so attached to their owners.\n",
      "2. **Dogs have a powerful sense of smell**: Dogs have up to 300 million olfactory receptors in their noses, compared to only 6 million in humans. This means they can detect smells that are too faint for us to detect, and they use their sense of smell to navigate their environment, detect food, and even detect health issues in their owners.\n",
      "3. **Dogs are highly trainable**: Dogs are able to learn a wide range of behaviors and tasks through training and conditioning. They are capable of learning hundreds of commands and tasks, from simple obedience behaviors like \"sit\" and \"stay\" to complex tasks like search and rescue, agility, and service work. Their ability to learn and adapt makes them valuable companions and working animals.\n"
     ]
    }
   ],
   "source": [
    "final_runnable_response = response.content\n",
    "print(final_runnable_response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Extend\n",
    "continually extend the chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words is: 103\n",
      "NATURAL LANGUAGE PROCESSING (NLP) IS A SUBFIELD OF ARTIFICIAL INTELLIGENCE THAT ENABLES COMPUTERS TO UNDERSTAND, INTERPRET, AND GENERATE HUMAN LANGUAGE. IT INVOLVES DEVELOPING ALGORITHMS AND STATISTICAL MODELS THAT ANALYZE AND PROCESS HUMAN LANGUAGE DATA, SUCH AS TEXT OR SPEECH. NLP IS USED IN APPLICATIONS LIKE LANGUAGE TRANSLATION, SENTIMENT ANALYSIS, SPEECH RECOGNITION, AND TEXT SUMMARIZATION. IT INVOLVES TASKS LIKE TOKENIZATION, STEMMING, LEMMATIZATION, AND PARSING TO BREAK DOWN LANGUAGE INTO MEANINGFUL COMPONENTS, AND MACHINE LEARNING TO TRAIN MODELS ON LARGE DATASETS. NLP HAS NUMEROUS APPLICATIONS IN INDUSTRIES LIKE CUSTOMER SERVICE, HEALTHCARE, AND EDUCATION, AND HAS THE POTENTIAL TO REVOLUTIONIZE THE WAY HUMANS INTERACT WITH TECHNOLOGY.\n"
     ]
    }
   ],
   "source": [
    "# simple create the half chain with LCEL and add more chains with Runnable Lambda\n",
    "\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnableLambda\n",
    "\n",
    "prompt_template = PromptTemplate(\n",
    "    template=\"Tell me about {topic}. in exactly {number} words.\",\n",
    "    input_variables=[\"topic\", \"number\"]\n",
    ")\n",
    "\n",
    "# prompt_template = ChatPromptTemplate.from_messages(\n",
    "#     [\n",
    "#         (\"system\", \"Tell me about in {number} words exactly..\"),\n",
    "#         (\"human\", \"Describe about {topic}\")\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "parser = RunnableLambda(lambda x: x.content)\n",
    "uppercase_output = RunnableLambda(lambda x: x.upper())\n",
    "count = RunnableLambda(lambda x: f\"The total number of words is: {len(x.split())}\\n{x}\")\n",
    "\n",
    "chain = prompt_template | model | parser | uppercase_output | count\n",
    "\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"Natural Language Processing\",\n",
    "    \"number\": 100,\n",
    "})\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Natural Language Processing (NLP) is a subfield of artificial intelligence that focuses on the interaction between computers and human language. NLP enables computers to understand, interpret, and generate human language, allowing for applications such as language translation, sentiment analysis, and text summarization. NLP involves various tasks, including tokenization, part-of-speech tagging, named entity recognition, and parsing. Techniques used in NLP include machine learning, deep learning, and rule-based systems. NLP has numerous applications, including chatbots, virtual assistants, and natural language interfaces for search engines and other systems. Its potential to improve human-computer interaction is vast and rapidly growing.'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# can use any output parser but the input and outout should be keep in mind while creating the chain\n",
    "chain = prompt_template | model | StrOutputParser()\n",
    "response = chain.invoke({\n",
    "    \"topic\": \"Natural Language Processing\",\n",
    "    \"number\": 100,\n",
    "})\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                         -> analyzechain1\n",
    "# prompt -> model -> Parser               -> final response\n",
    "#                         -> analyzechain2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are an expert product reviewer.\"),\n",
    "        (\"human\", \"List the main 2 features of the product {product_name} with each feature not exceeding 10 words.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "def analyze_pros(features):\n",
    "    \"\"\"This function will return the prompt for the pros of the features.\n",
    "    \n",
    "    args: \n",
    "    features: str\n",
    "    \"\"\"\n",
    "    pros_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert product reviewer.\"),\n",
    "            (\"human\", \"Given these features:\\n{features}\\n, List the one main pros of these features.\")\n",
    "        ]\n",
    "    )\n",
    "    return pros_template.format_prompt(features=features)\n",
    "\n",
    "def analyze_cons(features):\n",
    "    \"\"\"This function will return the prompt for the cons of the features.\n",
    "    \n",
    "    args:\n",
    "    features: str\n",
    "    \"\"\"\n",
    "    cons_template = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\"system\", \"You are an expert product reviewer.\"),\n",
    "            (\"human\", \"Given these features:\\n{features}\\n, List the one cons of these features.\")\n",
    "        ]\n",
    "    )\n",
    "    return cons_template.format_prompt(features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[SystemMessage(content='You are an expert product reviewer.'), HumanMessage(content='Given these features:\\n1. Good battery life\\n2. Good camera quality\\n3. Good display\\n, List the one main pros of these features.')]\n",
      "messages=[SystemMessage(content='You are an expert product reviewer.'), HumanMessage(content='Given these features:\\n1. Expensive\\n2. Heavy\\n3. Not user-friendly\\n, List the one cons of these features.')]\n"
     ]
    }
   ],
   "source": [
    "# Testing the prompt\n",
    "\n",
    "pros_prompt = analyze_pros(\"1. Good battery life\\n2. Good camera quality\\n3. Good display\")\n",
    "cons_prompt = analyze_cons(\"1. Expensive\\n2. Heavy\\n3. Not user-friendly\")\n",
    "\n",
    "print(pros_prompt)\n",
    "print(cons_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating branch for the Pros and Cons chain\n",
    "\n",
    "# careful when chaining here, the output of the analyze_pros and analyze_cons should be the input for the model\n",
    "pros_branch_chain = (\n",
    "    RunnableLambda(lambda x:  analyze_pros(x)) | model | StrOutputParser()\n",
    ")\n",
    "\n",
    "cons_branch_chain = (\n",
    "    RunnableLambda(lambda x: analyze_cons(x)) | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the output from the branch that was parallel:\n",
      " {'branches': {'pros': 'Based on the features, here are the one main pros for each:\\n\\n1. Improved Cameras with Enhanced Night Mode Capability:\\n\\t* Main Pro: Better low-light photography, allowing users to take high-quality photos even in dimly lit environments.\\n2. Fastest Chip Ever - A15 Bionic Performance Boost:\\n\\t* Main Pro: Enhanced overall device performance, enabling smoother and faster execution of tasks, apps, and games.', 'cons': \"Based on the features mentioned, here's one potential con for each:\\n\\n1. Improved Cameras with Enhanced Night Mode Capability:\\nCon: The improved camera features may lead to increased power consumption, which could result in shorter battery life, especially when using the camera in low-light conditions.\\n\\n2. Fastest Chip Ever - A15 Bionic Performance Boost:\\nCon: The increased processing power may also lead to faster battery drain, as the phone will be working harder to handle demanding tasks and games. This could result in users needing to charge their phone more frequently.\"}}\n"
     ]
    }
   ],
   "source": [
    "# Creating a combined chain using LCEL with RunnableParallel\n",
    "from langchain_core.runnables import RunnableParallel\n",
    "\n",
    "def combine_pros_cons(output_from_parallel_branches):\n",
    "    print(\"Here is the output from the branch that was parallel:\\n\", output_from_parallel_branches)\n",
    "    pros = output_from_parallel_branches[\"branches\"][\"pros\"]\n",
    "    cons = output_from_parallel_branches[\"branches\"][\"cons\"]\n",
    "    return f\"Pros:\\n{pros}\\n\\nCons:\\n{cons}\"\n",
    "\n",
    "chain = (\n",
    "    prompt_template\n",
    "    | model\n",
    "    | StrOutputParser()\n",
    "    | RunnableParallel(\n",
    "        branches={\n",
    "            \"pros\": pros_branch_chain,\n",
    "            \"cons\": cons_branch_chain\n",
    "        }\n",
    "    )\n",
    "    # Here we get the dict from the parallel branch chain and this is how we get the pros and cons separately\n",
    "    | RunnableLambda(lambda x: combine_pros_cons(x))\n",
    ")\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"product_name\": \"iPhone 13\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pros:\n",
      "Based on the features, here are the one main pros for each:\n",
      "\n",
      "1. Improved Cameras with Enhanced Night Mode Capability:\n",
      "\t* Main Pro: Better low-light photography, allowing users to take high-quality photos even in dimly lit environments.\n",
      "2. Fastest Chip Ever - A15 Bionic Performance Boost:\n",
      "\t* Main Pro: Enhanced overall device performance, enabling smoother and faster execution of tasks, apps, and games.\n",
      "\n",
      "Cons:\n",
      "Based on the features mentioned, here's one potential con for each:\n",
      "\n",
      "1. Improved Cameras with Enhanced Night Mode Capability:\n",
      "Con: The improved camera features may lead to increased power consumption, which could result in shorter battery life, especially when using the camera in low-light conditions.\n",
      "\n",
      "2. Fastest Chip Ever - A15 Bionic Performance Boost:\n",
      "Con: The increased processing power may also lead to faster battery drain, as the phone will be working harder to handle demanding tasks and games. This could result in users needing to charge their phone more frequently.\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chain Branching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#                                   -> Negative chain\n",
    "#                                   -> positive chain  \n",
    "# prompt -> classification model -> parser \n",
    "#                                   -> Neutral chain\n",
    "#                                   -> Escalate chain\n",
    "\n",
    "# here we will use RunnableBranch like checking if else condition for the chain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "positive_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a customer service representative Alisa.\"),\n",
    "        (\"human\", \"The customer has given a positive feedback: {feedback} Please respond politely with thank you note,\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "negative_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a customer service representative Jenny.\"),\n",
    "        (\"human\", \"The customer has given a negative feedback: {feedback} Please respond politely with an apology note.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "neutral_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a customer service representative Erika.\"),\n",
    "        (\"human\", \"The customer has given a neutral feedback: {feedback} Please respond politely with a neutral note.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "escalate_feedback_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a customer service representative Samantha.\"),\n",
    "        (\"human\", \"The customer has given a feedback: {feedback} Please escalate this to the higher authority.\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "classification_template = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a customer service representative.\"),\n",
    "        (\"human\", \"Classify the feedback: {feedback} as Positive, Negative, Neutral, Escalate, nofeedback.\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating branches\n",
    "from langchain_core.runnables import RunnableBranch\n",
    "\n",
    "branches = RunnableBranch(\n",
    "    (\n",
    "        # positive feedback chain\n",
    "        lambda x: \"positive\" in x, # condition\n",
    "        positive_feedback_template | model | StrOutputParser(),\n",
    "    ),\n",
    "    (\n",
    "        # negative feedback chain\n",
    "        lambda x: \"negative\" in x, # condition\n",
    "        negative_feedback_template | model | StrOutputParser(),\n",
    "    ),\n",
    "    (\n",
    "        # neutral feedback chain\n",
    "        lambda x: \"neutral\" in x, # condition\n",
    "        neutral_feedback_template | model | StrOutputParser(),\n",
    "    ),\n",
    "    # RunnableBranch must have default chain so here it is\n",
    "    # otherwise error: RunnableBranch default must be runnable, callable or mapping.\n",
    "    escalate_feedback_template | model | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thank you so much for taking the time to share your thoughts about our product! We appreciate your honesty and value your feedback. It's great to hear that you've enjoyed some of the features and found them to be beneficial. However, we apologize that the high price was a drawback for you. We understand that our product may not fit every budget, and we're always looking for ways to improve and make it more accessible to our customers. Your input will definitely help us in our future product development and pricing strategy. Once again, thank you for your feedback, and we hope you'll continue to consider our product in the future.\n"
     ]
    }
   ],
   "source": [
    "classification_chain = classification_template | model | StrOutputParser()\n",
    "\n",
    "# combining the classification and response generation into one chain\n",
    "chain = classification_chain | branches\n",
    "\n",
    "response = chain.invoke(\n",
    "    {\n",
    "        \"feedback\": \"This product has good features but it is expensive.\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
