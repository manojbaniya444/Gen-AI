{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LangChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "\n",
    "client = OpenAI(openai_api_key=\"sk-1234567890abcdef1234567890abcdef\")\n",
    "\n",
    "prompt = \"Translate the following English text to French: 'Hello, how are you?'\"\n",
    "\n",
    "response = client.predict((prompt).strip())\n",
    "\n",
    "## Quota Exceeded to OpenAI API\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero Shot Prompting\n",
    "# We directly ask the question to the model without providing any context or examples.\n",
    "prompt_zero_shot = \"Can you tell me the capital of Nepal?\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few Shot Prompting\n",
    "# We provide a few examples to the model to help it understand the context.\n",
    "english_text = \"Hello, how are you?\"\n",
    "prompt_few_shot = f\"Translate the following English text to French: {english_text}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Templates:\n",
    "[Prompt langchain](./notes/Prompt.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template = PromptTemplate.from_template(\"Translate the following English text to Nepali: {english_text}\")\n",
    "\n",
    "prompt1 = prompt_template.format(english_text= \"I am a Computer Engineering student from Nepal.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the following English text to Nepali: I am a Computer Engineering student from Nepal.'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt2 = prompt_template.format(english_text= \"I am a Software Engineer working in the United States.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Translate the following English text to Nepali: I am a Software Engineer working in the United States.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use this prompt and get the response from the model\n",
    "response = client.predict((prompt1).strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent:\n",
    "[Agent langchain](./notes/Agent.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Can you tell me who won the recent FIFA world cup?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.predict((prompt).strip())\n",
    "\n",
    "# The response will be out of date as the model is not aware of the recent events."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For extracting a real time info use serp api by using this serp api for google search, then extract the information in real time\n",
    "\n",
    "- Can use google search api\n",
    "- Can use wikipedia agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentType\n",
    "from langchain.agents import load_tools\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.llms import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(openai_api_key=\"sk-1234567890abcdef1234567890abcdef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tool = load_tools([\"serpapi\"], serpapi_api_key=\"secret\", llm=client)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = initialize_agent(tool, client, agent = AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.run(\"Can you tell me who won the recent FIFA world cup?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chain\n",
    "[Chain langchain](./notes//Chain.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt = PromptTemplate.from_template(\"Can you tell me who won the recent FIFA world cup {date}?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm = client, prompt = prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"2002\").strip()\n",
    "chain.run(\"2004\").strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we want to combine multiple chain and set a sequence for that we use simplesequential chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=[\"startup_name\"],\n",
    "    template=\"Can you provide me with information about the startup {startup name}?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name_chain = LLMChain(llm=client,prompt=prompt_template_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=[\"item1\"],\n",
    "    template=\"Suggest some strategy for {item1}.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy_chain = LLMChain(llm=client,prompt=prompt_template_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SimpleSequentialChain\n",
    "\n",
    "chain = SimpleSequentialChain(chains = [name_chain, strategy_chain])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain.run(\"Artificial Intelligence\")\n",
    "# Output will be of last chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Another one "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables=[\"cusine_type\"],\n",
    "    template=\"I want to open a restaurant for {cusine_type} food. Can you suggest me a name for my restaurant?\"\n",
    ")\n",
    "\n",
    "name_chain = LLMChain(llm=client, prompt=prompt_template_name, output_key = \"restaurant_name\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_items = PromptTemplate(\n",
    "    input_variables=[\"restaurant_name\"],\n",
    "    template=\"Can you suggest me menu items for {restaurant_name}?\"\n",
    ")\n",
    "\n",
    "food_items_chain = LLMChain(llm=client, prompt=prompt_template_items, output_key = \"menu_items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import SequentialChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SequentialChain(\n",
    "    chains=[name_chain,food_items_chain],\n",
    "    input_variables=[\"cuisine_type\"],\n",
    "    output_variables=[\"restaurant_name\",\"menu_items\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain(\"cuisine_type\",\"Italian\")\n",
    "\n",
    "# This will return all the outputs of the chains."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Loaders\n",
    "[document loader from official langchain](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='# Chain\\n> Forming a core connection among one or several large language models in certain sophisticated applications, it becomes necessary to chain LLMs together either with each other or with other elements.', metadata={'source': './notes/Chain.md'})]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"./notes/Chain.md\")\n",
    "loader.load()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
